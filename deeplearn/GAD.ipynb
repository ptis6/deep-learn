{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200], Step [200/600], d_loss: 0.0380, g_loss: 4.3761, D(x): 0.99, D(G(z)): 0.03\n",
      "Epoch [0/200], Step [400/600], d_loss: 0.0532, g_loss: 6.1023, D(x): 0.97, D(G(z)): 0.02\n",
      "Epoch [0/200], Step [600/600], d_loss: 0.0458, g_loss: 4.8051, D(x): 0.98, D(G(z)): 0.02\n",
      "Epoch [1/200], Step [200/600], d_loss: 0.0310, g_loss: 6.0029, D(x): 0.99, D(G(z)): 0.01\n",
      "Epoch [1/200], Step [400/600], d_loss: 0.2351, g_loss: 3.4980, D(x): 0.90, D(G(z)): 0.05\n",
      "Epoch [1/200], Step [600/600], d_loss: 0.1568, g_loss: 7.6516, D(x): 0.96, D(G(z)): 0.09\n",
      "Epoch [2/200], Step [200/600], d_loss: 0.5237, g_loss: 2.5571, D(x): 0.82, D(G(z)): 0.15\n",
      "Epoch [2/200], Step [400/600], d_loss: 0.2069, g_loss: 4.5404, D(x): 0.94, D(G(z)): 0.09\n",
      "Epoch [2/200], Step [600/600], d_loss: 0.6847, g_loss: 3.1632, D(x): 0.86, D(G(z)): 0.31\n",
      "Epoch [3/200], Step [200/600], d_loss: 0.9319, g_loss: 1.8768, D(x): 0.82, D(G(z)): 0.36\n",
      "Epoch [3/200], Step [400/600], d_loss: 1.3164, g_loss: 4.5750, D(x): 0.78, D(G(z)): 0.34\n",
      "Epoch [3/200], Step [600/600], d_loss: 0.1853, g_loss: 3.9864, D(x): 0.95, D(G(z)): 0.10\n",
      "Epoch [4/200], Step [200/600], d_loss: 0.6012, g_loss: 3.0649, D(x): 0.81, D(G(z)): 0.17\n",
      "Epoch [4/200], Step [400/600], d_loss: 0.2325, g_loss: 2.8421, D(x): 0.92, D(G(z)): 0.10\n",
      "Epoch [4/200], Step [600/600], d_loss: 0.2340, g_loss: 3.8014, D(x): 0.90, D(G(z)): 0.06\n",
      "Epoch [5/200], Step [200/600], d_loss: 0.1519, g_loss: 3.8312, D(x): 0.96, D(G(z)): 0.08\n",
      "Epoch [5/200], Step [400/600], d_loss: 0.1519, g_loss: 3.1451, D(x): 0.95, D(G(z)): 0.08\n",
      "Epoch [5/200], Step [600/600], d_loss: 0.2612, g_loss: 3.7808, D(x): 0.94, D(G(z)): 0.08\n",
      "Epoch [6/200], Step [200/600], d_loss: 0.1880, g_loss: 3.9175, D(x): 0.91, D(G(z)): 0.05\n",
      "Epoch [6/200], Step [400/600], d_loss: 0.3810, g_loss: 3.7752, D(x): 0.84, D(G(z)): 0.04\n",
      "Epoch [6/200], Step [600/600], d_loss: 0.1086, g_loss: 4.2847, D(x): 0.95, D(G(z)): 0.03\n",
      "Epoch [7/200], Step [200/600], d_loss: 0.3972, g_loss: 2.7802, D(x): 0.84, D(G(z)): 0.04\n",
      "Epoch [7/200], Step [400/600], d_loss: 0.1081, g_loss: 4.6224, D(x): 0.97, D(G(z)): 0.05\n",
      "Epoch [7/200], Step [600/600], d_loss: 0.1279, g_loss: 5.0563, D(x): 0.95, D(G(z)): 0.04\n",
      "Epoch [8/200], Step [200/600], d_loss: 0.1689, g_loss: 5.2343, D(x): 0.97, D(G(z)): 0.08\n",
      "Epoch [8/200], Step [400/600], d_loss: 0.0631, g_loss: 4.6960, D(x): 0.99, D(G(z)): 0.05\n",
      "Epoch [8/200], Step [600/600], d_loss: 0.0545, g_loss: 5.8891, D(x): 0.98, D(G(z)): 0.02\n",
      "Epoch [9/200], Step [200/600], d_loss: 0.0803, g_loss: 5.2634, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [9/200], Step [400/600], d_loss: 0.1058, g_loss: 6.5661, D(x): 0.97, D(G(z)): 0.03\n",
      "Epoch [9/200], Step [600/600], d_loss: 0.1309, g_loss: 6.9778, D(x): 0.98, D(G(z)): 0.08\n",
      "Epoch [10/200], Step [200/600], d_loss: 0.1412, g_loss: 6.9706, D(x): 0.99, D(G(z)): 0.07\n",
      "Epoch [10/200], Step [400/600], d_loss: 0.1470, g_loss: 4.2447, D(x): 0.94, D(G(z)): 0.04\n",
      "Epoch [10/200], Step [600/600], d_loss: 0.0630, g_loss: 6.0402, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [11/200], Step [200/600], d_loss: 0.1635, g_loss: 6.8738, D(x): 0.96, D(G(z)): 0.05\n",
      "Epoch [11/200], Step [400/600], d_loss: 0.2136, g_loss: 7.6746, D(x): 0.90, D(G(z)): 0.01\n",
      "Epoch [11/200], Step [600/600], d_loss: 0.1145, g_loss: 4.7414, D(x): 0.96, D(G(z)): 0.05\n",
      "Epoch [12/200], Step [200/600], d_loss: 0.3531, g_loss: 3.5895, D(x): 0.90, D(G(z)): 0.02\n",
      "Epoch [12/200], Step [400/600], d_loss: 0.3294, g_loss: 4.8098, D(x): 0.91, D(G(z)): 0.04\n",
      "Epoch [12/200], Step [600/600], d_loss: 0.1537, g_loss: 6.2845, D(x): 0.95, D(G(z)): 0.02\n",
      "Epoch [13/200], Step [200/600], d_loss: 0.3594, g_loss: 4.8413, D(x): 0.89, D(G(z)): 0.06\n",
      "Epoch [13/200], Step [400/600], d_loss: 0.1807, g_loss: 4.1918, D(x): 0.97, D(G(z)): 0.12\n",
      "Epoch [13/200], Step [600/600], d_loss: 0.2999, g_loss: 5.2298, D(x): 0.90, D(G(z)): 0.03\n",
      "Epoch [14/200], Step [200/600], d_loss: 0.3667, g_loss: 4.3107, D(x): 0.96, D(G(z)): 0.20\n",
      "Epoch [14/200], Step [400/600], d_loss: 0.2515, g_loss: 4.1225, D(x): 0.94, D(G(z)): 0.11\n",
      "Epoch [14/200], Step [600/600], d_loss: 0.3233, g_loss: 4.2470, D(x): 0.93, D(G(z)): 0.10\n",
      "Epoch [15/200], Step [200/600], d_loss: 0.3718, g_loss: 4.2671, D(x): 0.88, D(G(z)): 0.07\n",
      "Epoch [15/200], Step [400/600], d_loss: 0.2259, g_loss: 3.8062, D(x): 0.94, D(G(z)): 0.06\n",
      "Epoch [15/200], Step [600/600], d_loss: 0.2080, g_loss: 2.7688, D(x): 0.95, D(G(z)): 0.10\n",
      "Epoch [16/200], Step [200/600], d_loss: 0.5065, g_loss: 2.1241, D(x): 0.85, D(G(z)): 0.03\n",
      "Epoch [16/200], Step [400/600], d_loss: 0.2640, g_loss: 3.5599, D(x): 0.95, D(G(z)): 0.13\n",
      "Epoch [16/200], Step [600/600], d_loss: 0.2666, g_loss: 3.8743, D(x): 0.97, D(G(z)): 0.16\n",
      "Epoch [17/200], Step [200/600], d_loss: 0.3712, g_loss: 3.9266, D(x): 0.86, D(G(z)): 0.06\n",
      "Epoch [17/200], Step [400/600], d_loss: 0.4006, g_loss: 4.6978, D(x): 0.91, D(G(z)): 0.09\n",
      "Epoch [17/200], Step [600/600], d_loss: 0.4098, g_loss: 3.4466, D(x): 0.90, D(G(z)): 0.07\n",
      "Epoch [18/200], Step [200/600], d_loss: 0.3193, g_loss: 4.5358, D(x): 0.87, D(G(z)): 0.02\n",
      "Epoch [18/200], Step [400/600], d_loss: 0.3112, g_loss: 3.4547, D(x): 0.88, D(G(z)): 0.07\n",
      "Epoch [18/200], Step [600/600], d_loss: 0.6222, g_loss: 3.5698, D(x): 0.91, D(G(z)): 0.30\n",
      "Epoch [19/200], Step [200/600], d_loss: 0.4567, g_loss: 2.7873, D(x): 0.84, D(G(z)): 0.10\n",
      "Epoch [19/200], Step [400/600], d_loss: 0.4872, g_loss: 3.1131, D(x): 0.89, D(G(z)): 0.21\n",
      "Epoch [19/200], Step [600/600], d_loss: 0.2173, g_loss: 4.0178, D(x): 0.94, D(G(z)): 0.09\n",
      "Epoch [20/200], Step [200/600], d_loss: 0.6123, g_loss: 3.7188, D(x): 0.80, D(G(z)): 0.04\n",
      "Epoch [20/200], Step [400/600], d_loss: 0.3681, g_loss: 3.2596, D(x): 0.93, D(G(z)): 0.18\n",
      "Epoch [20/200], Step [600/600], d_loss: 0.4404, g_loss: 4.6383, D(x): 0.93, D(G(z)): 0.18\n",
      "Epoch [21/200], Step [200/600], d_loss: 0.3875, g_loss: 2.8459, D(x): 0.92, D(G(z)): 0.17\n",
      "Epoch [21/200], Step [400/600], d_loss: 0.3559, g_loss: 3.2773, D(x): 0.89, D(G(z)): 0.11\n",
      "Epoch [21/200], Step [600/600], d_loss: 0.3652, g_loss: 4.5171, D(x): 0.90, D(G(z)): 0.13\n",
      "Epoch [22/200], Step [200/600], d_loss: 0.3574, g_loss: 3.2565, D(x): 0.90, D(G(z)): 0.13\n",
      "Epoch [22/200], Step [400/600], d_loss: 0.3340, g_loss: 3.0164, D(x): 0.95, D(G(z)): 0.17\n",
      "Epoch [22/200], Step [600/600], d_loss: 0.2046, g_loss: 4.1019, D(x): 0.93, D(G(z)): 0.05\n",
      "Epoch [23/200], Step [200/600], d_loss: 0.1841, g_loss: 3.6236, D(x): 0.92, D(G(z)): 0.06\n",
      "Epoch [23/200], Step [400/600], d_loss: 0.2785, g_loss: 5.0978, D(x): 0.93, D(G(z)): 0.11\n",
      "Epoch [23/200], Step [600/600], d_loss: 0.2943, g_loss: 4.7476, D(x): 0.92, D(G(z)): 0.11\n",
      "Epoch [24/200], Step [200/600], d_loss: 0.3608, g_loss: 4.0369, D(x): 0.92, D(G(z)): 0.10\n",
      "Epoch [24/200], Step [400/600], d_loss: 0.3099, g_loss: 3.6234, D(x): 0.95, D(G(z)): 0.15\n",
      "Epoch [24/200], Step [600/600], d_loss: 0.2416, g_loss: 4.2655, D(x): 0.92, D(G(z)): 0.07\n",
      "Epoch [25/200], Step [200/600], d_loss: 0.5002, g_loss: 3.9591, D(x): 0.87, D(G(z)): 0.08\n",
      "Epoch [25/200], Step [400/600], d_loss: 0.2239, g_loss: 5.1339, D(x): 0.88, D(G(z)): 0.02\n",
      "Epoch [25/200], Step [600/600], d_loss: 0.2375, g_loss: 4.9581, D(x): 0.92, D(G(z)): 0.04\n",
      "Epoch [26/200], Step [200/600], d_loss: 0.5101, g_loss: 4.7214, D(x): 0.83, D(G(z)): 0.03\n",
      "Epoch [26/200], Step [400/600], d_loss: 0.2565, g_loss: 4.8533, D(x): 0.98, D(G(z)): 0.16\n",
      "Epoch [26/200], Step [600/600], d_loss: 0.1798, g_loss: 5.4917, D(x): 0.94, D(G(z)): 0.04\n",
      "Epoch [27/200], Step [200/600], d_loss: 0.1365, g_loss: 5.1605, D(x): 0.94, D(G(z)): 0.04\n",
      "Epoch [27/200], Step [400/600], d_loss: 0.2098, g_loss: 3.2829, D(x): 0.95, D(G(z)): 0.10\n",
      "Epoch [27/200], Step [600/600], d_loss: 0.2425, g_loss: 4.5582, D(x): 0.91, D(G(z)): 0.08\n",
      "Epoch [28/200], Step [200/600], d_loss: 0.3290, g_loss: 4.8083, D(x): 0.90, D(G(z)): 0.07\n",
      "Epoch [28/200], Step [400/600], d_loss: 0.2165, g_loss: 4.8999, D(x): 0.96, D(G(z)): 0.10\n",
      "Epoch [28/200], Step [600/600], d_loss: 0.2972, g_loss: 3.8982, D(x): 0.94, D(G(z)): 0.09\n",
      "Epoch [29/200], Step [200/600], d_loss: 0.2520, g_loss: 4.8452, D(x): 0.92, D(G(z)): 0.06\n",
      "Epoch [29/200], Step [400/600], d_loss: 0.4529, g_loss: 3.3551, D(x): 0.89, D(G(z)): 0.16\n",
      "Epoch [29/200], Step [600/600], d_loss: 0.3794, g_loss: 4.6662, D(x): 0.86, D(G(z)): 0.06\n",
      "Epoch [30/200], Step [200/600], d_loss: 0.5293, g_loss: 4.0980, D(x): 0.81, D(G(z)): 0.05\n",
      "Epoch [30/200], Step [400/600], d_loss: 0.2475, g_loss: 4.4462, D(x): 0.91, D(G(z)): 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Step [600/600], d_loss: 0.4565, g_loss: 4.1811, D(x): 0.86, D(G(z)): 0.07\n",
      "Epoch [31/200], Step [200/600], d_loss: 0.3227, g_loss: 2.8308, D(x): 0.91, D(G(z)): 0.11\n",
      "Epoch [31/200], Step [400/600], d_loss: 0.2546, g_loss: 4.8864, D(x): 0.91, D(G(z)): 0.06\n",
      "Epoch [31/200], Step [600/600], d_loss: 0.5045, g_loss: 4.8381, D(x): 0.84, D(G(z)): 0.12\n",
      "Epoch [32/200], Step [200/600], d_loss: 0.2846, g_loss: 4.1228, D(x): 0.92, D(G(z)): 0.12\n",
      "Epoch [32/200], Step [400/600], d_loss: 0.2835, g_loss: 3.9550, D(x): 0.92, D(G(z)): 0.11\n",
      "Epoch [32/200], Step [600/600], d_loss: 0.4019, g_loss: 3.6037, D(x): 0.87, D(G(z)): 0.10\n",
      "Epoch [33/200], Step [200/600], d_loss: 0.2474, g_loss: 4.1444, D(x): 0.93, D(G(z)): 0.09\n",
      "Epoch [33/200], Step [400/600], d_loss: 0.2466, g_loss: 3.4604, D(x): 0.90, D(G(z)): 0.07\n",
      "Epoch [33/200], Step [600/600], d_loss: 0.5793, g_loss: 2.2675, D(x): 0.95, D(G(z)): 0.28\n",
      "Epoch [34/200], Step [200/600], d_loss: 0.3996, g_loss: 3.2407, D(x): 0.95, D(G(z)): 0.19\n",
      "Epoch [34/200], Step [400/600], d_loss: 0.4435, g_loss: 3.6832, D(x): 0.83, D(G(z)): 0.09\n",
      "Epoch [34/200], Step [600/600], d_loss: 0.4473, g_loss: 4.0414, D(x): 0.83, D(G(z)): 0.04\n",
      "Epoch [35/200], Step [200/600], d_loss: 0.4244, g_loss: 3.6238, D(x): 0.82, D(G(z)): 0.06\n",
      "Epoch [35/200], Step [400/600], d_loss: 0.4889, g_loss: 3.1115, D(x): 0.82, D(G(z)): 0.09\n",
      "Epoch [35/200], Step [600/600], d_loss: 0.4881, g_loss: 3.0117, D(x): 0.83, D(G(z)): 0.10\n",
      "Epoch [36/200], Step [200/600], d_loss: 0.3594, g_loss: 4.2855, D(x): 0.87, D(G(z)): 0.11\n",
      "Epoch [36/200], Step [400/600], d_loss: 0.3344, g_loss: 3.9149, D(x): 0.94, D(G(z)): 0.18\n",
      "Epoch [36/200], Step [600/600], d_loss: 0.4289, g_loss: 4.0305, D(x): 0.85, D(G(z)): 0.11\n",
      "Epoch [37/200], Step [200/600], d_loss: 0.4215, g_loss: 3.0613, D(x): 0.93, D(G(z)): 0.21\n",
      "Epoch [37/200], Step [400/600], d_loss: 0.4785, g_loss: 2.5327, D(x): 0.90, D(G(z)): 0.20\n",
      "Epoch [37/200], Step [600/600], d_loss: 0.4161, g_loss: 4.3449, D(x): 0.86, D(G(z)): 0.13\n",
      "Epoch [38/200], Step [200/600], d_loss: 0.4086, g_loss: 2.8773, D(x): 0.88, D(G(z)): 0.14\n",
      "Epoch [38/200], Step [400/600], d_loss: 0.3848, g_loss: 5.1445, D(x): 0.83, D(G(z)): 0.06\n",
      "Epoch [38/200], Step [600/600], d_loss: 0.2183, g_loss: 4.1034, D(x): 0.95, D(G(z)): 0.10\n",
      "Epoch [39/200], Step [200/600], d_loss: 0.3604, g_loss: 3.8779, D(x): 0.90, D(G(z)): 0.12\n",
      "Epoch [39/200], Step [400/600], d_loss: 0.3505, g_loss: 3.5092, D(x): 0.89, D(G(z)): 0.11\n",
      "Epoch [39/200], Step [600/600], d_loss: 0.2219, g_loss: 4.6046, D(x): 0.91, D(G(z)): 0.05\n",
      "Epoch [40/200], Step [200/600], d_loss: 0.4653, g_loss: 4.1454, D(x): 0.89, D(G(z)): 0.20\n",
      "Epoch [40/200], Step [400/600], d_loss: 0.4254, g_loss: 3.2007, D(x): 0.89, D(G(z)): 0.17\n",
      "Epoch [40/200], Step [600/600], d_loss: 0.5192, g_loss: 3.6470, D(x): 0.92, D(G(z)): 0.19\n",
      "Epoch [41/200], Step [200/600], d_loss: 0.5776, g_loss: 3.4558, D(x): 0.91, D(G(z)): 0.26\n",
      "Epoch [41/200], Step [400/600], d_loss: 0.5223, g_loss: 3.2572, D(x): 0.93, D(G(z)): 0.25\n",
      "Epoch [41/200], Step [600/600], d_loss: 0.8075, g_loss: 2.0646, D(x): 0.89, D(G(z)): 0.31\n",
      "Epoch [42/200], Step [200/600], d_loss: 0.4746, g_loss: 3.9805, D(x): 0.81, D(G(z)): 0.09\n",
      "Epoch [42/200], Step [400/600], d_loss: 0.4335, g_loss: 2.8677, D(x): 0.92, D(G(z)): 0.20\n",
      "Epoch [42/200], Step [600/600], d_loss: 0.4759, g_loss: 3.2726, D(x): 0.85, D(G(z)): 0.13\n",
      "Epoch [43/200], Step [200/600], d_loss: 0.7928, g_loss: 2.8235, D(x): 0.78, D(G(z)): 0.22\n",
      "Epoch [43/200], Step [400/600], d_loss: 0.4746, g_loss: 3.4095, D(x): 0.80, D(G(z)): 0.08\n",
      "Epoch [43/200], Step [600/600], d_loss: 0.8930, g_loss: 1.6523, D(x): 0.74, D(G(z)): 0.21\n",
      "Epoch [44/200], Step [200/600], d_loss: 0.6007, g_loss: 2.7035, D(x): 0.84, D(G(z)): 0.21\n",
      "Epoch [44/200], Step [400/600], d_loss: 0.6581, g_loss: 1.6985, D(x): 0.80, D(G(z)): 0.15\n",
      "Epoch [44/200], Step [600/600], d_loss: 0.6826, g_loss: 2.7990, D(x): 0.78, D(G(z)): 0.17\n",
      "Epoch [45/200], Step [200/600], d_loss: 0.6011, g_loss: 3.4094, D(x): 0.76, D(G(z)): 0.12\n",
      "Epoch [45/200], Step [400/600], d_loss: 0.6490, g_loss: 2.5250, D(x): 0.80, D(G(z)): 0.20\n",
      "Epoch [45/200], Step [600/600], d_loss: 0.7813, g_loss: 1.9148, D(x): 0.84, D(G(z)): 0.30\n",
      "Epoch [46/200], Step [200/600], d_loss: 0.4623, g_loss: 2.9028, D(x): 0.83, D(G(z)): 0.14\n",
      "Epoch [46/200], Step [400/600], d_loss: 0.6328, g_loss: 3.0019, D(x): 0.84, D(G(z)): 0.23\n",
      "Epoch [46/200], Step [600/600], d_loss: 0.5586, g_loss: 2.3300, D(x): 0.83, D(G(z)): 0.20\n",
      "Epoch [47/200], Step [200/600], d_loss: 0.7213, g_loss: 2.4685, D(x): 0.90, D(G(z)): 0.34\n",
      "Epoch [47/200], Step [400/600], d_loss: 0.8150, g_loss: 2.5427, D(x): 0.73, D(G(z)): 0.19\n",
      "Epoch [47/200], Step [600/600], d_loss: 0.5425, g_loss: 1.9639, D(x): 0.81, D(G(z)): 0.14\n",
      "Epoch [48/200], Step [200/600], d_loss: 0.5826, g_loss: 3.3712, D(x): 0.83, D(G(z)): 0.18\n",
      "Epoch [48/200], Step [400/600], d_loss: 0.4056, g_loss: 3.2400, D(x): 0.88, D(G(z)): 0.17\n",
      "Epoch [48/200], Step [600/600], d_loss: 0.2669, g_loss: 3.1440, D(x): 0.90, D(G(z)): 0.10\n",
      "Epoch [49/200], Step [200/600], d_loss: 0.4490, g_loss: 2.4050, D(x): 0.86, D(G(z)): 0.15\n",
      "Epoch [49/200], Step [400/600], d_loss: 0.4168, g_loss: 3.2741, D(x): 0.90, D(G(z)): 0.19\n",
      "Epoch [49/200], Step [600/600], d_loss: 0.5129, g_loss: 4.0004, D(x): 0.89, D(G(z)): 0.22\n",
      "Epoch [50/200], Step [200/600], d_loss: 0.5752, g_loss: 2.0784, D(x): 0.92, D(G(z)): 0.28\n",
      "Epoch [50/200], Step [400/600], d_loss: 0.6113, g_loss: 3.2347, D(x): 0.88, D(G(z)): 0.26\n",
      "Epoch [50/200], Step [600/600], d_loss: 0.5832, g_loss: 2.4053, D(x): 0.87, D(G(z)): 0.25\n",
      "Epoch [51/200], Step [200/600], d_loss: 0.5324, g_loss: 3.5524, D(x): 0.87, D(G(z)): 0.21\n",
      "Epoch [51/200], Step [400/600], d_loss: 0.4058, g_loss: 3.7823, D(x): 0.85, D(G(z)): 0.12\n",
      "Epoch [51/200], Step [600/600], d_loss: 0.7688, g_loss: 3.2935, D(x): 0.74, D(G(z)): 0.18\n",
      "Epoch [52/200], Step [200/600], d_loss: 0.3898, g_loss: 3.5763, D(x): 0.85, D(G(z)): 0.10\n",
      "Epoch [52/200], Step [400/600], d_loss: 0.4791, g_loss: 2.1940, D(x): 0.93, D(G(z)): 0.27\n",
      "Epoch [52/200], Step [600/600], d_loss: 0.5569, g_loss: 2.8936, D(x): 0.79, D(G(z)): 0.13\n",
      "Epoch [53/200], Step [200/600], d_loss: 0.6432, g_loss: 2.3960, D(x): 0.78, D(G(z)): 0.17\n",
      "Epoch [53/200], Step [400/600], d_loss: 0.3958, g_loss: 3.0451, D(x): 0.87, D(G(z)): 0.15\n",
      "Epoch [53/200], Step [600/600], d_loss: 0.6385, g_loss: 2.9175, D(x): 0.82, D(G(z)): 0.21\n",
      "Epoch [54/200], Step [200/600], d_loss: 0.7768, g_loss: 2.3689, D(x): 0.79, D(G(z)): 0.26\n",
      "Epoch [54/200], Step [400/600], d_loss: 0.5640, g_loss: 2.8105, D(x): 0.79, D(G(z)): 0.17\n",
      "Epoch [54/200], Step [600/600], d_loss: 0.3991, g_loss: 2.4182, D(x): 0.86, D(G(z)): 0.15\n",
      "Epoch [55/200], Step [200/600], d_loss: 0.3589, g_loss: 2.9854, D(x): 0.89, D(G(z)): 0.15\n",
      "Epoch [55/200], Step [400/600], d_loss: 0.5213, g_loss: 3.1306, D(x): 0.79, D(G(z)): 0.09\n",
      "Epoch [55/200], Step [600/600], d_loss: 0.6157, g_loss: 3.2068, D(x): 0.74, D(G(z)): 0.12\n",
      "Epoch [56/200], Step [200/600], d_loss: 0.5333, g_loss: 2.4761, D(x): 0.85, D(G(z)): 0.19\n",
      "Epoch [56/200], Step [400/600], d_loss: 0.5460, g_loss: 2.6004, D(x): 0.82, D(G(z)): 0.20\n",
      "Epoch [56/200], Step [600/600], d_loss: 0.5948, g_loss: 2.5988, D(x): 0.90, D(G(z)): 0.30\n",
      "Epoch [57/200], Step [200/600], d_loss: 0.4725, g_loss: 3.4717, D(x): 0.83, D(G(z)): 0.14\n",
      "Epoch [57/200], Step [400/600], d_loss: 0.4713, g_loss: 2.9898, D(x): 0.85, D(G(z)): 0.16\n",
      "Epoch [57/200], Step [600/600], d_loss: 0.5120, g_loss: 2.1045, D(x): 0.89, D(G(z)): 0.22\n",
      "Epoch [58/200], Step [200/600], d_loss: 0.5838, g_loss: 3.1353, D(x): 0.87, D(G(z)): 0.25\n",
      "Epoch [58/200], Step [400/600], d_loss: 0.7383, g_loss: 3.6609, D(x): 0.75, D(G(z)): 0.19\n",
      "Epoch [58/200], Step [600/600], d_loss: 0.4958, g_loss: 2.2322, D(x): 0.84, D(G(z)): 0.19\n",
      "Epoch [59/200], Step [200/600], d_loss: 0.7476, g_loss: 2.5445, D(x): 0.75, D(G(z)): 0.17\n",
      "Epoch [59/200], Step [400/600], d_loss: 0.5630, g_loss: 2.3511, D(x): 0.82, D(G(z)): 0.18\n",
      "Epoch [59/200], Step [600/600], d_loss: 0.6804, g_loss: 2.2952, D(x): 0.74, D(G(z)): 0.16\n",
      "Epoch [60/200], Step [200/600], d_loss: 0.6785, g_loss: 2.1691, D(x): 0.85, D(G(z)): 0.28\n",
      "Epoch [60/200], Step [400/600], d_loss: 0.8094, g_loss: 2.0667, D(x): 0.72, D(G(z)): 0.20\n",
      "Epoch [60/200], Step [600/600], d_loss: 0.7274, g_loss: 2.5614, D(x): 0.83, D(G(z)): 0.26\n",
      "Epoch [61/200], Step [200/600], d_loss: 0.6347, g_loss: 2.3038, D(x): 0.81, D(G(z)): 0.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/200], Step [400/600], d_loss: 0.6814, g_loss: 2.2926, D(x): 0.83, D(G(z)): 0.25\n",
      "Epoch [61/200], Step [600/600], d_loss: 0.5814, g_loss: 2.0921, D(x): 0.86, D(G(z)): 0.22\n",
      "Epoch [62/200], Step [200/600], d_loss: 0.6261, g_loss: 2.6960, D(x): 0.78, D(G(z)): 0.16\n",
      "Epoch [62/200], Step [400/600], d_loss: 0.5426, g_loss: 2.7437, D(x): 0.84, D(G(z)): 0.21\n",
      "Epoch [62/200], Step [600/600], d_loss: 0.6266, g_loss: 2.1382, D(x): 0.79, D(G(z)): 0.22\n",
      "Epoch [63/200], Step [200/600], d_loss: 0.5674, g_loss: 2.9002, D(x): 0.81, D(G(z)): 0.15\n",
      "Epoch [63/200], Step [400/600], d_loss: 0.5054, g_loss: 2.5707, D(x): 0.82, D(G(z)): 0.16\n",
      "Epoch [63/200], Step [600/600], d_loss: 0.7020, g_loss: 2.5435, D(x): 0.72, D(G(z)): 0.13\n",
      "Epoch [64/200], Step [200/600], d_loss: 0.8878, g_loss: 1.8565, D(x): 0.79, D(G(z)): 0.34\n",
      "Epoch [64/200], Step [400/600], d_loss: 0.5012, g_loss: 2.9842, D(x): 0.81, D(G(z)): 0.12\n",
      "Epoch [64/200], Step [600/600], d_loss: 0.6495, g_loss: 2.2167, D(x): 0.78, D(G(z)): 0.18\n",
      "Epoch [65/200], Step [200/600], d_loss: 0.7158, g_loss: 2.1727, D(x): 0.92, D(G(z)): 0.37\n",
      "Epoch [65/200], Step [400/600], d_loss: 0.6707, g_loss: 2.3433, D(x): 0.81, D(G(z)): 0.23\n",
      "Epoch [65/200], Step [600/600], d_loss: 0.6354, g_loss: 1.9790, D(x): 0.76, D(G(z)): 0.18\n",
      "Epoch [66/200], Step [200/600], d_loss: 0.4798, g_loss: 1.6981, D(x): 0.86, D(G(z)): 0.20\n",
      "Epoch [66/200], Step [400/600], d_loss: 0.7630, g_loss: 1.9197, D(x): 0.76, D(G(z)): 0.26\n",
      "Epoch [66/200], Step [600/600], d_loss: 0.9384, g_loss: 2.3136, D(x): 0.71, D(G(z)): 0.25\n",
      "Epoch [67/200], Step [200/600], d_loss: 0.5783, g_loss: 2.5748, D(x): 0.77, D(G(z)): 0.17\n",
      "Epoch [67/200], Step [400/600], d_loss: 0.6404, g_loss: 2.3656, D(x): 0.74, D(G(z)): 0.18\n",
      "Epoch [67/200], Step [600/600], d_loss: 0.5678, g_loss: 2.2772, D(x): 0.80, D(G(z)): 0.18\n",
      "Epoch [68/200], Step [200/600], d_loss: 0.7059, g_loss: 1.7106, D(x): 0.74, D(G(z)): 0.21\n",
      "Epoch [68/200], Step [400/600], d_loss: 0.5101, g_loss: 3.1490, D(x): 0.83, D(G(z)): 0.18\n",
      "Epoch [68/200], Step [600/600], d_loss: 0.6414, g_loss: 2.0518, D(x): 0.89, D(G(z)): 0.31\n",
      "Epoch [69/200], Step [200/600], d_loss: 0.8008, g_loss: 2.0058, D(x): 0.75, D(G(z)): 0.23\n",
      "Epoch [69/200], Step [400/600], d_loss: 0.6533, g_loss: 1.5764, D(x): 0.77, D(G(z)): 0.19\n",
      "Epoch [69/200], Step [600/600], d_loss: 0.7581, g_loss: 2.2740, D(x): 0.80, D(G(z)): 0.27\n",
      "Epoch [70/200], Step [200/600], d_loss: 0.7771, g_loss: 1.4619, D(x): 0.77, D(G(z)): 0.26\n",
      "Epoch [70/200], Step [400/600], d_loss: 0.8017, g_loss: 1.8956, D(x): 0.78, D(G(z)): 0.27\n",
      "Epoch [70/200], Step [600/600], d_loss: 0.6679, g_loss: 2.7808, D(x): 0.82, D(G(z)): 0.25\n",
      "Epoch [71/200], Step [200/600], d_loss: 0.9430, g_loss: 1.8626, D(x): 0.70, D(G(z)): 0.30\n",
      "Epoch [71/200], Step [400/600], d_loss: 0.7756, g_loss: 2.2489, D(x): 0.77, D(G(z)): 0.25\n",
      "Epoch [71/200], Step [600/600], d_loss: 0.7071, g_loss: 2.2332, D(x): 0.77, D(G(z)): 0.21\n",
      "Epoch [72/200], Step [200/600], d_loss: 1.1321, g_loss: 1.9296, D(x): 0.84, D(G(z)): 0.48\n",
      "Epoch [72/200], Step [400/600], d_loss: 0.6579, g_loss: 2.3965, D(x): 0.76, D(G(z)): 0.21\n",
      "Epoch [72/200], Step [600/600], d_loss: 0.7576, g_loss: 2.6659, D(x): 0.85, D(G(z)): 0.32\n",
      "Epoch [73/200], Step [200/600], d_loss: 0.7305, g_loss: 1.8613, D(x): 0.76, D(G(z)): 0.24\n",
      "Epoch [73/200], Step [400/600], d_loss: 0.7201, g_loss: 2.1833, D(x): 0.82, D(G(z)): 0.30\n",
      "Epoch [73/200], Step [600/600], d_loss: 0.5515, g_loss: 2.9953, D(x): 0.81, D(G(z)): 0.19\n",
      "Epoch [74/200], Step [200/600], d_loss: 0.6914, g_loss: 2.0105, D(x): 0.81, D(G(z)): 0.28\n",
      "Epoch [74/200], Step [400/600], d_loss: 0.7338, g_loss: 2.0289, D(x): 0.74, D(G(z)): 0.22\n",
      "Epoch [74/200], Step [600/600], d_loss: 0.7205, g_loss: 2.1494, D(x): 0.80, D(G(z)): 0.26\n",
      "Epoch [75/200], Step [200/600], d_loss: 0.7493, g_loss: 2.2219, D(x): 0.74, D(G(z)): 0.20\n",
      "Epoch [75/200], Step [400/600], d_loss: 0.6854, g_loss: 1.9278, D(x): 0.79, D(G(z)): 0.25\n",
      "Epoch [75/200], Step [600/600], d_loss: 0.7147, g_loss: 1.6953, D(x): 0.73, D(G(z)): 0.18\n",
      "Epoch [76/200], Step [200/600], d_loss: 1.0459, g_loss: 1.7140, D(x): 0.72, D(G(z)): 0.33\n",
      "Epoch [76/200], Step [400/600], d_loss: 0.7215, g_loss: 1.4209, D(x): 0.76, D(G(z)): 0.22\n",
      "Epoch [76/200], Step [600/600], d_loss: 0.6749, g_loss: 2.6716, D(x): 0.74, D(G(z)): 0.20\n",
      "Epoch [77/200], Step [200/600], d_loss: 0.7733, g_loss: 1.7075, D(x): 0.78, D(G(z)): 0.27\n",
      "Epoch [77/200], Step [400/600], d_loss: 0.5396, g_loss: 2.5800, D(x): 0.81, D(G(z)): 0.20\n",
      "Epoch [77/200], Step [600/600], d_loss: 1.1485, g_loss: 1.9427, D(x): 0.57, D(G(z)): 0.19\n",
      "Epoch [78/200], Step [200/600], d_loss: 0.6006, g_loss: 2.1407, D(x): 0.86, D(G(z)): 0.27\n",
      "Epoch [78/200], Step [400/600], d_loss: 0.9113, g_loss: 3.1317, D(x): 0.67, D(G(z)): 0.18\n",
      "Epoch [78/200], Step [600/600], d_loss: 0.8437, g_loss: 1.9564, D(x): 0.79, D(G(z)): 0.30\n",
      "Epoch [79/200], Step [200/600], d_loss: 0.7557, g_loss: 2.0936, D(x): 0.75, D(G(z)): 0.27\n",
      "Epoch [79/200], Step [400/600], d_loss: 0.8867, g_loss: 1.8837, D(x): 0.73, D(G(z)): 0.30\n",
      "Epoch [79/200], Step [600/600], d_loss: 0.7819, g_loss: 2.6670, D(x): 0.71, D(G(z)): 0.19\n",
      "Epoch [80/200], Step [200/600], d_loss: 0.7943, g_loss: 1.6377, D(x): 0.73, D(G(z)): 0.24\n",
      "Epoch [80/200], Step [400/600], d_loss: 0.9578, g_loss: 1.5990, D(x): 0.75, D(G(z)): 0.36\n",
      "Epoch [80/200], Step [600/600], d_loss: 0.7444, g_loss: 1.6615, D(x): 0.75, D(G(z)): 0.24\n",
      "Epoch [81/200], Step [200/600], d_loss: 1.0375, g_loss: 2.2877, D(x): 0.71, D(G(z)): 0.32\n",
      "Epoch [81/200], Step [400/600], d_loss: 0.7137, g_loss: 2.5240, D(x): 0.78, D(G(z)): 0.24\n",
      "Epoch [81/200], Step [600/600], d_loss: 0.9459, g_loss: 2.2798, D(x): 0.68, D(G(z)): 0.24\n",
      "Epoch [82/200], Step [200/600], d_loss: 0.7668, g_loss: 1.8122, D(x): 0.81, D(G(z)): 0.31\n",
      "Epoch [82/200], Step [400/600], d_loss: 0.7626, g_loss: 2.2866, D(x): 0.78, D(G(z)): 0.25\n",
      "Epoch [82/200], Step [600/600], d_loss: 0.7062, g_loss: 1.9330, D(x): 0.75, D(G(z)): 0.24\n",
      "Epoch [83/200], Step [200/600], d_loss: 0.7280, g_loss: 1.9253, D(x): 0.75, D(G(z)): 0.23\n",
      "Epoch [83/200], Step [400/600], d_loss: 1.0375, g_loss: 1.6233, D(x): 0.66, D(G(z)): 0.23\n",
      "Epoch [83/200], Step [600/600], d_loss: 0.6888, g_loss: 2.6595, D(x): 0.78, D(G(z)): 0.26\n",
      "Epoch [84/200], Step [200/600], d_loss: 0.7905, g_loss: 1.9312, D(x): 0.73, D(G(z)): 0.24\n",
      "Epoch [84/200], Step [400/600], d_loss: 0.5579, g_loss: 2.9235, D(x): 0.78, D(G(z)): 0.15\n",
      "Epoch [84/200], Step [600/600], d_loss: 0.8281, g_loss: 2.2547, D(x): 0.71, D(G(z)): 0.21\n",
      "Epoch [85/200], Step [200/600], d_loss: 0.6426, g_loss: 2.6493, D(x): 0.76, D(G(z)): 0.19\n",
      "Epoch [85/200], Step [400/600], d_loss: 0.6096, g_loss: 2.0929, D(x): 0.81, D(G(z)): 0.20\n",
      "Epoch [85/200], Step [600/600], d_loss: 0.9569, g_loss: 1.9096, D(x): 0.80, D(G(z)): 0.35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 97\u001b[0m\n\u001b[0;32m     93\u001b[0m d_loss\u001b[38;5;241m=\u001b[39md_loss_fake\u001b[38;5;241m+\u001b[39md_loss_real\n\u001b[0;32m     95\u001b[0m re_grad()\n\u001b[1;32m---> 97\u001b[0m \u001b[43md_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m d_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    101\u001b[0m z\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(batch_size,latent_size)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mE:\\an\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\an\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:193\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    189\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    192\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 193\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32mE:\\an\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:89\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import  transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "device=device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "\n",
    "sample_dir = 'D:/data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "])\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(root='D:/data',\n",
    "                                   train=True,\n",
    "                                   transform=transform,\n",
    "                                   download=True)\n",
    "data_loader = DataLoader(dataset=mnist,\n",
    "                         batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "D=nn.Sequential(\n",
    "    nn.Linear(image_size,hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size,hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "G=nn.Sequential(\n",
    "    nn.Linear(latent_size,hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,image_size),\n",
    "    nn.Tanh()\n",
    ")\n",
    "\n",
    "D = D.to(device)\n",
    "G = G.to(device)\n",
    "\n",
    "criterion=nn.BCELoss()\n",
    "\n",
    "d_opt=torch.optim.Adam(D.parameters(),lr=0.0002)\n",
    "g_opt=torch.optim.Adam(G.parameters(),lr=0.0002)\n",
    "\n",
    "def denorm(x):\n",
    "    out=(x+1)/2\n",
    "    return out.clamp(0,1)\n",
    "\n",
    "def re_grad():\n",
    "    d_opt.zero_grad()\n",
    "    g_opt.zero_grad()\n",
    "\n",
    "total_step=len(data_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(data_loader):\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        outputs=D(images)\n",
    "        d_loss_real=criterion(outputs,real_labels)\n",
    "\n",
    "        real_score=outputs\n",
    "\n",
    "        z=torch.randn(batch_size,latent_size).to(device)\n",
    "\n",
    "        fake_images=G(z)\n",
    "\n",
    "\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        d_loss=d_loss_fake+d_loss_real\n",
    "\n",
    "        re_grad()\n",
    "\n",
    "        d_loss.backward()\n",
    "\n",
    "        d_opt.step()\n",
    "\n",
    "        z=torch.randn(batch_size,latent_size).to(device)\n",
    "\n",
    "        fake_images=G(z)\n",
    "        outputs=D(fake_images)\n",
    "\n",
    "        g_loss=criterion(outputs,real_labels)\n",
    "\n",
    "        re_grad()\n",
    "\n",
    "        g_loss.backward()\n",
    "\n",
    "        g_opt.step()\n",
    "\n",
    "        if (i + 1) % 200 == 0 :\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
    "                  .format(epoch, num_epochs, i + 1, total_step, d_loss.item(), g_loss.item(),\n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    if (epoch + 1) == 1 :\n",
    "        images = images.reshape(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "\n",
    "        # Save sampled images\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch + 1)))\n",
    "\n",
    "torch.save(G.state_dict(), 'D:/G.pt')\n",
    "torch.save(D.state_dict(), 'D:/D.pt')\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print('时间为：',execution_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
